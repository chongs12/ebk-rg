# Enterprise Knowledge Base (EKB) - 技术亮点文档

本文档详细介绍了 EKB 项目的核心技术选型、架构设计创新点以及关键功能的实现细节。

## 1. 核心技术栈

### 1.1 后端框架：Go + Gin + CloudWeGo
*   **选型理由**: Go 语言具有高并发、低延迟的特性，非常适合 I/O 密集型的微服务场景。Gin 提供了轻量级的 Web 框架支持，而 CloudWeGo/Eino 提供了强大的 LLM 应用开发套件。
*   **优势**: 编译速度快，部署体积小，Goroutine 模型轻松应对高并发请求。

### 1.2 向量数据库：Milvus
*   **选型理由**: 开源界最流行的向量数据库之一，支持亿级向量检索，提供多种索引类型（IVF_FLAT, HNSW 等）。
*   **优势**: 高性能的近似最近邻 (ANN) 搜索，原生支持云原生部署。

### 1.3 大模型集成：Volcengine Ark (豆包)
*   **选型理由**: 字节跳动火山引擎提供的企业级大模型服务，具有极高的中文理解与生成能力。
*   **优势**: 稳定可靠的 API 服务，支持长上下文窗口，性价比高。

### 1.4 消息队列：RabbitMQ
*   **选型理由**: 成熟可靠的 AMQP 消息中间件，用于解耦文档上传与向量化处理流程。
*   **优势**: 保证消息不丢失（持久化），支持削峰填谷，避免突发上传流量压垮向量化服务。**已配置死信队列 (DLQ)**，确保处理失败的消息（如格式错误的文档）会被转移至独立队列进行人工排查，防止阻塞主业务流程。

### 1.5 可观测性：OpenTelemetry + Prometheus + Jaeger
*   **选型理由**: 云原生时代的监控标准。
*   **优势**: 统一的 Trace/Metrics 采集标准，全链路追踪能够快速定位微服务间的调用延迟与故障。

---

## 2. 架构亮点

### 2.1 微服务解耦与异步处理
系统将文档处理流程拆分为同步与异步两个阶段：
*   **同步阶段**: 文档服务接收上传请求，进行基础校验并落库 MySQL，立即返回响应给用户，提升用户体验。
*   **异步阶段**: 文档服务发送消息至 RabbitMQ，向量服务作为消费者监听队列。向量化（Embedding）这一耗时操作在后台异步执行，支持水平扩展消费者实例以提升处理吞吐量。

### 2.2 统一 API 网关 (Gateway)
*   **统一入口**: 所有客户端请求通过 Gateway 进入，屏蔽了后端微服务的复杂性。
*   **聚合请求**: 网关层负责请求转发与聚合，降低了客户端与服务端的交互次数。
*   **服务发现**: 结合 Kubernetes Service 或 Docker DNS，实现动态服务发现。

### 2.3 部门级 RBAC 权限控制
在 RAG 检索链路中深度集成了权限校验：
*   **设计**: 在 `internal/common/models` 中扩展了 `Visibility` 和 `DepartmentID` 字段。
*   **实现**: 在 `rag_query` 服务中，检索回来的向量分块（Chunks）不仅仅按相似度排序，还会立即与当前用户的部门权限进行匹配过滤 (`filterChunksByPermission`)。确保用户只能“看到”其有权访问的文档片段生成的答案。

---

## 3. 关键技术实现

### 3.1 高质量中文文本切分
针对中文语境，实现了定制化的切分算法 (`internal/vector/service.go: splitChineseText`)：
*   **语义完整性**: 优先依据中文标点符号（`。！？`）和换行符进行切分，避免将一个完整的句子切断。
*   **长度控制**: 在保持语义完整的前提下，对超长句子进行强制截断，确保不超过 Embedding 模型的 Token 限制。
*   **滑动窗口**: 支持块与块之间的重叠（Overlap），减少上下文丢失（代码中预留了逻辑）。

### 3.2 检索增强生成 (RAG) 优化
*   **混合检索策略**: 系统设计支持结合关键词检索（BM25）与向量检索（Dense Retrieval），目前主要实现基于 Milvus 的向量检索。
*   **Prompt 工程**: 在 `rag_query/service.go` 中精心设计了 System Prompt，约束 LLM 仅依据提供的上下文回答，有效减少幻觉（Hallucination）。
    ```go
    "你是企业知识库的检索增强问答助手。严格依据提供的上下文回答，无法回答时请明确说明。"
    ```
*   **来源溯源**: 每一个生成的回答都会附带引用来源（文档名、段落预览），增加了回答的可信度。

### 3.3 全链路分布式追踪
在 `pkg/tracing` 中封装了 OpenTelemetry 初始化逻辑，并在每个 Gin Handler 和 gRPC 调用中注入 Trace Context。
*   **效果**: 在 Jaeger 面板中可以清晰看到一个 `Ask` 请求从 Gateway -> Auth -> Query -> Vector -> Milvus/Ark 的完整调用链及各阶段耗时。

---

## 4. 项目成果

### 4.1 性能指标
*   **查询延迟**: 在 P99 情况下，RAG 查询（包含检索与生成）平均响应时间控制在 3 秒以内（取决于模型生成速度）。
*   **并发能力**: 单节点向量服务可支持每分钟处理 50+ 文档（平均 10MB/doc）的向量化任务。

### 4.2 解决的问题
*   **信息孤岛**: 打通了企业内部各部门的文档壁垒，同时通过权限控制保障了信息安全。
*   **检索效率**: 相比传统的关键词搜索，基于语义的向量检索能够理解用户的真实意图（如搜索“怎么报销”能匹配到“财务管理制度”）。

### 4.3 扩展性
*   **模型无关性**: 通过适配器模式（Eino），系统可以轻松切换不同的 Embedding 模型或 Chat 模型（如 OpenAI, Claude, Llama 3），无需修改核心业务逻辑。
*   **存储可替换**: 向量存储层通过接口抽象 (`Store` interface)，未来可适配 Elasticsearch 或 PGVector。
